WARNING 09-23 04:43:44 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:44 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:44 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:44 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:44 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:44 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:44 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:44 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:44 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:44 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:45 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:45 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:45 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:45 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:45 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 04:43:45 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
Namespace(backend='vllm', base_url='https://vgpu-test-15.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-5.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-16.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-3.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-2.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-10.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-7.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-14.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-4.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-12.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-9.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-11.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-6.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-8.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-13.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-1.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
============ Serving Benchmark Result ============
Successful requests:                     30189     
Benchmark duration (s):                  5160.80   
Total input tokens:                      6702976   
Total generated tokens:                  5558048   
Request throughput (req/s):              5.85      
Input token throughput (tok/s):          1298.83   
Output token throughput (tok/s):         1076.97   
---------------Time to First Token----------------
Mean TTFT (ms):                          4472.15   
Median TTFT (ms):                        5541.42   
P99 TTFT (ms):                           8067.36   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          41.22     
Median TPOT (ms):                        50.69     
P99 TPOT (ms):                           93.49     
---------------Inter-token Latency----------------
Mean ITL (ms):                           71.89     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4907.93   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     29976     
Benchmark duration (s):                  5162.37   
Total input tokens:                      6683794   
Total generated tokens:                  5517978   
Request throughput (req/s):              5.81      
Input token throughput (tok/s):          1294.71   
Output token throughput (tok/s):         1068.88   
---------------Time to First Token----------------
Mean TTFT (ms):                          4488.80   
Median TTFT (ms):                        5581.62   
P99 TTFT (ms):                           7987.92   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          41.14     
Median TPOT (ms):                        50.60     
P99 TPOT (ms):                           92.31     
---------------Inter-token Latency----------------
Mean ITL (ms):                           72.01     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4971.53   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     29643     
Benchmark duration (s):                  5163.78   
Total input tokens:                      6576101   
Total generated tokens:                  5482731   
Request throughput (req/s):              5.74      
Input token throughput (tok/s):          1273.51   
Output token throughput (tok/s):         1061.77   
---------------Time to First Token----------------
Mean TTFT (ms):                          4457.75   
Median TTFT (ms):                        5517.53   
P99 TTFT (ms):                           8005.34   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          41.23     
Median TPOT (ms):                        50.88     
P99 TPOT (ms):                           93.63     
---------------Inter-token Latency----------------
Mean ITL (ms):                           71.97     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4946.00   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     29633     
Benchmark duration (s):                  5165.05   
Total input tokens:                      6570951   
Total generated tokens:                  5460835   
Request throughput (req/s):              5.74      
Input token throughput (tok/s):          1272.19   
Output token throughput (tok/s):         1057.27   
---------------Time to First Token----------------
Mean TTFT (ms):                          4474.53   
Median TTFT (ms):                        5529.33   
P99 TTFT (ms):                           8042.76   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          41.27     
Median TPOT (ms):                        50.66     
P99 TPOT (ms):                           94.83     
---------------Inter-token Latency----------------
Mean ITL (ms):                           72.27     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4905.29   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     29805     
Benchmark duration (s):                  5164.94   
Total input tokens:                      6600668   
Total generated tokens:                  5501853   
Request throughput (req/s):              5.77      
Input token throughput (tok/s):          1277.98   
Output token throughput (tok/s):         1065.23   
---------------Time to First Token----------------
Mean TTFT (ms):                          4411.82   
Median TTFT (ms):                        5469.32   
P99 TTFT (ms):                           7793.64   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          40.79     
Median TPOT (ms):                        50.40     
P99 TPOT (ms):                           91.51     
---------------Inter-token Latency----------------
Mean ITL (ms):                           71.14     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4903.88   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     29573     
Benchmark duration (s):                  5165.85   
Total input tokens:                      6516343   
Total generated tokens:                  5463332   
Request throughput (req/s):              5.72      
Input token throughput (tok/s):          1261.43   
Output token throughput (tok/s):         1057.59   
---------------Time to First Token----------------
Mean TTFT (ms):                          4371.13   
Median TTFT (ms):                        5348.61   
P99 TTFT (ms):                           7962.66   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          40.31     
Median TPOT (ms):                        49.25     
P99 TPOT (ms):                           91.71     
---------------Inter-token Latency----------------
Mean ITL (ms):                           70.21     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4681.59   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     29905     
Benchmark duration (s):                  5166.87   
Total input tokens:                      6653020   
Total generated tokens:                  5518102   
Request throughput (req/s):              5.79      
Input token throughput (tok/s):          1287.63   
Output token throughput (tok/s):         1067.98   
---------------Time to First Token----------------
Mean TTFT (ms):                          4599.93   
Median TTFT (ms):                        5712.27   
P99 TTFT (ms):                           8127.34   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          42.45     
Median TPOT (ms):                        52.16     
P99 TPOT (ms):                           95.96     
---------------Inter-token Latency----------------
Mean ITL (ms):                           74.14     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5105.28   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     29751     
Benchmark duration (s):                  5167.00   
Total input tokens:                      6540769   
Total generated tokens:                  5534320   
Request throughput (req/s):              5.76      
Input token throughput (tok/s):          1265.87   
Output token throughput (tok/s):         1071.09   
---------------Time to First Token----------------
Mean TTFT (ms):                          4540.31   
Median TTFT (ms):                        5597.38   
P99 TTFT (ms):                           8262.12   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          42.02     
Median TPOT (ms):                        51.46     
P99 TPOT (ms):                           96.13     
---------------Inter-token Latency----------------
Mean ITL (ms):                           72.90     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4952.67   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     29986     
Benchmark duration (s):                  5166.94   
Total input tokens:                      6621660   
Total generated tokens:                  5535126   
Request throughput (req/s):              5.80      
Input token throughput (tok/s):          1281.54   
Output token throughput (tok/s):         1071.26   
---------------Time to First Token----------------
Mean TTFT (ms):                          4564.64   
Median TTFT (ms):                        5645.15   
P99 TTFT (ms):                           8293.31   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          42.02     
Median TPOT (ms):                        51.63     
P99 TPOT (ms):                           96.68     
---------------Inter-token Latency----------------
Mean ITL (ms):                           73.10     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4972.17   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     29798     
Benchmark duration (s):                  5167.08   
Total input tokens:                      6612940   
Total generated tokens:                  5542354   
Request throughput (req/s):              5.77      
Input token throughput (tok/s):          1279.82   
Output token throughput (tok/s):         1072.63   
---------------Time to First Token----------------
Mean TTFT (ms):                          4498.95   
Median TTFT (ms):                        5522.67   
P99 TTFT (ms):                           8045.26   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          41.70     
Median TPOT (ms):                        50.97     
P99 TPOT (ms):                           95.21     
---------------Inter-token Latency----------------
Mean ITL (ms):                           72.56     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4884.79   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     29888     
Benchmark duration (s):                  5166.26   
Total input tokens:                      6617031   
Total generated tokens:                  5481069   
Request throughput (req/s):              5.79      
Input token throughput (tok/s):          1280.82   
Output token throughput (tok/s):         1060.94   
---------------Time to First Token----------------
Mean TTFT (ms):                          4552.92   
Median TTFT (ms):                        5599.05   
P99 TTFT (ms):                           8288.97   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          41.89     
Median TPOT (ms):                        51.28     
P99 TPOT (ms):                           96.76     
---------------Inter-token Latency----------------
Mean ITL (ms):                           73.50     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5005.31   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     30007     
Benchmark duration (s):                  5168.84   
Total input tokens:                      6648697   
Total generated tokens:                  5534718   
Request throughput (req/s):              5.81      
Input token throughput (tok/s):          1286.30   
Output token throughput (tok/s):         1070.79   
---------------Time to First Token----------------
Mean TTFT (ms):                          4474.48   
Median TTFT (ms):                        5498.86   
P99 TTFT (ms):                           8035.76   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          41.19     
Median TPOT (ms):                        51.16     
P99 TPOT (ms):                           93.74     
---------------Inter-token Latency----------------
Mean ITL (ms):                           71.83     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4867.68   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     30252     
Benchmark duration (s):                  5168.87   
Total input tokens:                      6716170   
Total generated tokens:                  5578797   
Request throughput (req/s):              5.85      
Input token throughput (tok/s):          1299.35   
Output token throughput (tok/s):         1079.31   
---------------Time to First Token----------------
Mean TTFT (ms):                          4695.25   
Median TTFT (ms):                        5754.42   
P99 TTFT (ms):                           8583.00   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          43.23     
Median TPOT (ms):                        52.91     
P99 TPOT (ms):                           100.62    
---------------Inter-token Latency----------------
Mean ITL (ms):                           75.30     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5144.79   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     30306     
Benchmark duration (s):                  5169.23   
Total input tokens:                      6725101   
Total generated tokens:                  5545150   
Request throughput (req/s):              5.86      
Input token throughput (tok/s):          1300.99   
Output token throughput (tok/s):         1072.72   
---------------Time to First Token----------------
Mean TTFT (ms):                          4525.00   
Median TTFT (ms):                        5545.72   
P99 TTFT (ms):                           8137.81   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          41.66     
Median TPOT (ms):                        50.98     
P99 TPOT (ms):                           96.10     
---------------Inter-token Latency----------------
Mean ITL (ms):                           72.88     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4940.20   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     29727     
Benchmark duration (s):                  5169.74   
Total input tokens:                      6547750   
Total generated tokens:                  5496690   
Request throughput (req/s):              5.75      
Input token throughput (tok/s):          1266.55   
Output token throughput (tok/s):         1063.24   
---------------Time to First Token----------------
Mean TTFT (ms):                          4534.58   
Median TTFT (ms):                        5639.13   
P99 TTFT (ms):                           8182.17   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          42.04     
Median TPOT (ms):                        52.09     
P99 TPOT (ms):                           95.09     
---------------Inter-token Latency----------------
Mean ITL (ms):                           73.11     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5062.25   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     30033     
Benchmark duration (s):                  5288.05   
Total input tokens:                      6640880   
Total generated tokens:                  5542626   
Request throughput (req/s):              5.68      
Input token throughput (tok/s):          1255.83   
Output token throughput (tok/s):         1048.14   
---------------Time to First Token----------------
Mean TTFT (ms):                          4581.94   
Median TTFT (ms):                        5673.72   
P99 TTFT (ms):                           8230.75   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          42.46     
Median TPOT (ms):                        51.93     
P99 TPOT (ms):                           97.32     
---------------Inter-token Latency----------------
Mean ITL (ms):                           74.11     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5032.24   
==================================================
