WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 11:10:30 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
Namespace(backend='vllm', base_url='https://vgpu-test-9.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-3.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-2.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-14.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-16.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-8.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-15.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-10.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-5.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-6.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-12.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-7.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-11.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-13.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-4.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
Namespace(backend='vllm', base_url='https://vgpu-test-1.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=7.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 7.0
============ Serving Benchmark Result ============
Successful requests:                     31212     
Benchmark duration (s):                  5889.50   
Total input tokens:                      6890139   
Total generated tokens:                  5775416   
Request throughput (req/s):              5.30      
Input token throughput (tok/s):          1169.90   
Output token throughput (tok/s):         980.63    
---------------Time to First Token----------------
Mean TTFT (ms):                          4229.10   
Median TTFT (ms):                        5129.37   
P99 TTFT (ms):                           7573.14   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          38.53     
Median TPOT (ms):                        47.36     
P99 TPOT (ms):                           87.91     
---------------Inter-token Latency----------------
Mean ITL (ms):                           67.01     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4502.97   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31135     
Benchmark duration (s):                  5890.83   
Total input tokens:                      6898045   
Total generated tokens:                  5723218   
Request throughput (req/s):              5.29      
Input token throughput (tok/s):          1170.98   
Output token throughput (tok/s):         971.55    
---------------Time to First Token----------------
Mean TTFT (ms):                          4153.48   
Median TTFT (ms):                        5085.01   
P99 TTFT (ms):                           7389.27   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          37.99     
Median TPOT (ms):                        46.44     
P99 TPOT (ms):                           86.58     
---------------Inter-token Latency----------------
Mean ITL (ms):                           66.30     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4498.51   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31161     
Benchmark duration (s):                  5890.54   
Total input tokens:                      6888636   
Total generated tokens:                  5737600   
Request throughput (req/s):              5.29      
Input token throughput (tok/s):          1169.44   
Output token throughput (tok/s):         974.04    
---------------Time to First Token----------------
Mean TTFT (ms):                          4223.45   
Median TTFT (ms):                        5182.26   
P99 TTFT (ms):                           7627.58   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          38.49     
Median TPOT (ms):                        46.93     
P99 TPOT (ms):                           88.43     
---------------Inter-token Latency----------------
Mean ITL (ms):                           67.21     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4483.49   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31122     
Benchmark duration (s):                  5891.31   
Total input tokens:                      6875725   
Total generated tokens:                  5733748   
Request throughput (req/s):              5.28      
Input token throughput (tok/s):          1167.10   
Output token throughput (tok/s):         973.25    
---------------Time to First Token----------------
Mean TTFT (ms):                          4182.01   
Median TTFT (ms):                        5111.38   
P99 TTFT (ms):                           7496.07   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          37.97     
Median TPOT (ms):                        46.34     
P99 TPOT (ms):                           86.64     
---------------Inter-token Latency----------------
Mean ITL (ms):                           66.45     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4464.15   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31434     
Benchmark duration (s):                  5891.91   
Total input tokens:                      6964178   
Total generated tokens:                  5780376   
Request throughput (req/s):              5.34      
Input token throughput (tok/s):          1181.99   
Output token throughput (tok/s):         981.07    
---------------Time to First Token----------------
Mean TTFT (ms):                          4169.84   
Median TTFT (ms):                        5064.11   
P99 TTFT (ms):                           7545.04   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          37.82     
Median TPOT (ms):                        45.75     
P99 TPOT (ms):                           87.67     
---------------Inter-token Latency----------------
Mean ITL (ms):                           66.22     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4425.89   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     30777     
Benchmark duration (s):                  5891.72   
Total input tokens:                      6784379   
Total generated tokens:                  5669742   
Request throughput (req/s):              5.22      
Input token throughput (tok/s):          1151.51   
Output token throughput (tok/s):         962.32    
---------------Time to First Token----------------
Mean TTFT (ms):                          4029.36   
Median TTFT (ms):                        4882.52   
P99 TTFT (ms):                           7224.70   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          36.64     
Median TPOT (ms):                        43.98     
P99 TPOT (ms):                           85.10     
---------------Inter-token Latency----------------
Mean ITL (ms):                           64.06     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4276.59   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31533     
Benchmark duration (s):                  5891.66   
Total input tokens:                      6976648   
Total generated tokens:                  5805370   
Request throughput (req/s):              5.35      
Input token throughput (tok/s):          1184.16   
Output token throughput (tok/s):         985.35    
---------------Time to First Token----------------
Mean TTFT (ms):                          4244.78   
Median TTFT (ms):                        5207.82   
P99 TTFT (ms):                           7517.13   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          38.89     
Median TPOT (ms):                        47.80     
P99 TPOT (ms):                           88.71     
---------------Inter-token Latency----------------
Mean ITL (ms):                           67.95     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4623.65   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31680     
Benchmark duration (s):                  5891.75   
Total input tokens:                      7005529   
Total generated tokens:                  5850924   
Request throughput (req/s):              5.38      
Input token throughput (tok/s):          1189.04   
Output token throughput (tok/s):         993.07    
---------------Time to First Token----------------
Mean TTFT (ms):                          4263.81   
Median TTFT (ms):                        5264.10   
P99 TTFT (ms):                           7419.64   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          38.95     
Median TPOT (ms):                        48.64     
P99 TPOT (ms):                           87.21     
---------------Inter-token Latency----------------
Mean ITL (ms):                           67.88     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4734.12   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31552     
Benchmark duration (s):                  5892.96   
Total input tokens:                      7000128   
Total generated tokens:                  5811650   
Request throughput (req/s):              5.35      
Input token throughput (tok/s):          1187.88   
Output token throughput (tok/s):         986.20    
---------------Time to First Token----------------
Mean TTFT (ms):                          4213.91   
Median TTFT (ms):                        5146.45   
P99 TTFT (ms):                           7508.60   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          38.29     
Median TPOT (ms):                        47.11     
P99 TPOT (ms):                           87.27     
---------------Inter-token Latency----------------
Mean ITL (ms):                           66.85     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4524.50   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31877     
Benchmark duration (s):                  5892.99   
Total input tokens:                      7064496   
Total generated tokens:                  5910131   
Request throughput (req/s):              5.41      
Input token throughput (tok/s):          1198.80   
Output token throughput (tok/s):         1002.91   
---------------Time to First Token----------------
Mean TTFT (ms):                          4487.28   
Median TTFT (ms):                        5505.57   
P99 TTFT (ms):                           7985.49   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          41.01     
Median TPOT (ms):                        50.13     
P99 TPOT (ms):                           93.33     
---------------Inter-token Latency----------------
Mean ITL (ms):                           71.58     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4913.03   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     30998     
Benchmark duration (s):                  5894.39   
Total input tokens:                      6834401   
Total generated tokens:                  5705909   
Request throughput (req/s):              5.26      
Input token throughput (tok/s):          1159.48   
Output token throughput (tok/s):         968.02    
---------------Time to First Token----------------
Mean TTFT (ms):                          4261.42   
Median TTFT (ms):                        5210.74   
P99 TTFT (ms):                           7619.74   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          39.02     
Median TPOT (ms):                        48.08     
P99 TPOT (ms):                           89.38     
---------------Inter-token Latency----------------
Mean ITL (ms):                           67.93     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4655.53   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31834     
Benchmark duration (s):                  5894.26   
Total input tokens:                      7039861   
Total generated tokens:                  5885793   
Request throughput (req/s):              5.40      
Input token throughput (tok/s):          1194.36   
Output token throughput (tok/s):         998.56    
---------------Time to First Token----------------
Mean TTFT (ms):                          4229.75   
Median TTFT (ms):                        5205.84   
P99 TTFT (ms):                           7498.97   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          38.62     
Median TPOT (ms):                        47.60     
P99 TPOT (ms):                           87.78     
---------------Inter-token Latency----------------
Mean ITL (ms):                           67.18     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4536.92   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     30726     
Benchmark duration (s):                  5894.88   
Total input tokens:                      6776369   
Total generated tokens:                  5665067   
Request throughput (req/s):              5.21      
Input token throughput (tok/s):          1149.53   
Output token throughput (tok/s):         961.01    
---------------Time to First Token----------------
Mean TTFT (ms):                          4125.28   
Median TTFT (ms):                        4993.16   
P99 TTFT (ms):                           7429.89   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          37.27     
Median TPOT (ms):                        45.44     
P99 TPOT (ms):                           84.86     
---------------Inter-token Latency----------------
Mean ITL (ms):                           64.96     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4372.43   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31835     
Benchmark duration (s):                  5923.80   
Total input tokens:                      7065059   
Total generated tokens:                  5864412   
Request throughput (req/s):              5.37      
Input token throughput (tok/s):          1192.66   
Output token throughput (tok/s):         989.98    
---------------Time to First Token----------------
Mean TTFT (ms):                          4297.22   
Median TTFT (ms):                        5236.05   
P99 TTFT (ms):                           7608.39   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          39.01     
Median TPOT (ms):                        47.83     
P99 TPOT (ms):                           88.96     
---------------Inter-token Latency----------------
Mean ITL (ms):                           68.19     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4637.18   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31591     
Benchmark duration (s):                  5925.27   
Total input tokens:                      6977573   
Total generated tokens:                  5791457   
Request throughput (req/s):              5.33      
Input token throughput (tok/s):          1177.60   
Output token throughput (tok/s):         977.42    
---------------Time to First Token----------------
Mean TTFT (ms):                          4180.66   
Median TTFT (ms):                        5087.22   
P99 TTFT (ms):                           7576.32   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          37.89     
Median TPOT (ms):                        46.80     
P99 TPOT (ms):                           87.67     
---------------Inter-token Latency----------------
Mean ITL (ms):                           66.33     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4516.81   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31285     
Benchmark duration (s):                  5928.34   
Total input tokens:                      6901811   
Total generated tokens:                  5743873   
Request throughput (req/s):              5.28      
Input token throughput (tok/s):          1164.21   
Output token throughput (tok/s):         968.88    
---------------Time to First Token----------------
Mean TTFT (ms):                          4171.58   
Median TTFT (ms):                        5141.09   
P99 TTFT (ms):                           7495.51   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          38.07     
Median TPOT (ms):                        46.81     
P99 TPOT (ms):                           86.57     
---------------Inter-token Latency----------------
Mean ITL (ms):                           66.46     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            4577.86   
==================================================
