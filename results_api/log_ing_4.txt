WARNING 09-23 23:58:48 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:48 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:48 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:48 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:48 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:48 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:49 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:49 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:49 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:49 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:49 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:49 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:49 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:49 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:49 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-23 23:58:49 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
Namespace(backend='vllm', base_url='https://vgpu-test-15.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-7.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-13.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-12.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-6.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-9.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-8.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-16.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-1.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-3.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-10.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-11.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-4.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-2.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-5.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
Namespace(backend='vllm', base_url='https://vgpu-test-14.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=4.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 4.0
============ Serving Benchmark Result ============
Successful requests:                     40912     
Benchmark duration (s):                  10251.23  
Total input tokens:                      9094631   
Total generated tokens:                  7551749   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          887.17    
Output token throughput (tok/s):         736.67    
---------------Time to First Token----------------
Mean TTFT (ms):                          2856.18   
Median TTFT (ms):                        3304.70   
P99 TTFT (ms):                           5623.07   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          26.00     
Median TPOT (ms):                        31.16     
P99 TPOT (ms):                           63.80     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.41     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2920.41   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40904     
Benchmark duration (s):                  10251.22  
Total input tokens:                      9094886   
Total generated tokens:                  7547682   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          887.20    
Output token throughput (tok/s):         736.27    
---------------Time to First Token----------------
Mean TTFT (ms):                          2820.23   
Median TTFT (ms):                        3245.56   
P99 TTFT (ms):                           5527.04   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          25.77     
Median TPOT (ms):                        30.66     
P99 TPOT (ms):                           64.03     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.00     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2871.22   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40905     
Benchmark duration (s):                  10251.02  
Total input tokens:                      9093065   
Total generated tokens:                  7561722   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          887.04    
Output token throughput (tok/s):         737.66    
---------------Time to First Token----------------
Mean TTFT (ms):                          2862.32   
Median TTFT (ms):                        3315.49   
P99 TTFT (ms):                           5584.16   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          26.16     
Median TPOT (ms):                        31.45     
P99 TPOT (ms):                           63.67     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.68     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2941.24   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40909     
Benchmark duration (s):                  10250.99  
Total input tokens:                      9093296   
Total generated tokens:                  7552063   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          887.06    
Output token throughput (tok/s):         736.72    
---------------Time to First Token----------------
Mean TTFT (ms):                          2841.56   
Median TTFT (ms):                        3261.53   
P99 TTFT (ms):                           5641.41   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          25.98     
Median TPOT (ms):                        30.92     
P99 TPOT (ms):                           65.11     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.36     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2892.42   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40919     
Benchmark duration (s):                  10251.88  
Total input tokens:                      9096520   
Total generated tokens:                  7562004   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          887.30    
Output token throughput (tok/s):         737.62    
---------------Time to First Token----------------
Mean TTFT (ms):                          2836.32   
Median TTFT (ms):                        3285.55   
P99 TTFT (ms):                           5575.88   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          25.90     
Median TPOT (ms):                        31.12     
P99 TPOT (ms):                           63.37     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.21     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2916.05   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40908     
Benchmark duration (s):                  10251.68  
Total input tokens:                      9094597   
Total generated tokens:                  7555181   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          887.13    
Output token throughput (tok/s):         736.97    
---------------Time to First Token----------------
Mean TTFT (ms):                          2848.37   
Median TTFT (ms):                        3293.02   
P99 TTFT (ms):                           5538.18   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          25.98     
Median TPOT (ms):                        31.08     
P99 TPOT (ms):                           63.42     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.38     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2927.88   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40907     
Benchmark duration (s):                  10251.59  
Total input tokens:                      9094963   
Total generated tokens:                  7552286   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          887.18    
Output token throughput (tok/s):         736.69    
---------------Time to First Token----------------
Mean TTFT (ms):                          2852.38   
Median TTFT (ms):                        3297.92   
P99 TTFT (ms):                           5583.20   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          26.01     
Median TPOT (ms):                        31.15     
P99 TPOT (ms):                           63.85     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.42     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2920.64   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40923     
Benchmark duration (s):                  10251.91  
Total input tokens:                      9096167   
Total generated tokens:                  7563356   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          887.27    
Output token throughput (tok/s):         737.75    
---------------Time to First Token----------------
Mean TTFT (ms):                          2859.90   
Median TTFT (ms):                        3292.31   
P99 TTFT (ms):                           5619.91   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          26.11     
Median TPOT (ms):                        31.38     
P99 TPOT (ms):                           64.77     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.59     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2919.97   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40913     
Benchmark duration (s):                  10251.31  
Total input tokens:                      9093544   
Total generated tokens:                  7551805   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          887.06    
Output token throughput (tok/s):         736.67    
---------------Time to First Token----------------
Mean TTFT (ms):                          2839.48   
Median TTFT (ms):                        3270.95   
P99 TTFT (ms):                           5577.47   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          25.90     
Median TPOT (ms):                        31.00     
P99 TPOT (ms):                           63.64     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.23     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2897.37   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40901     
Benchmark duration (s):                  10251.95  
Total input tokens:                      9093644   
Total generated tokens:                  7544873   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          887.02    
Output token throughput (tok/s):         735.95    
---------------Time to First Token----------------
Mean TTFT (ms):                          2938.63   
Median TTFT (ms):                        3382.46   
P99 TTFT (ms):                           5800.48   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          26.81     
Median TPOT (ms):                        32.04     
P99 TPOT (ms):                           65.67     
---------------Inter-token Latency----------------
Mean ITL (ms):                           46.81     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2995.82   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40902     
Benchmark duration (s):                  10252.23  
Total input tokens:                      9092581   
Total generated tokens:                  7551202   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          886.89    
Output token throughput (tok/s):         736.54    
---------------Time to First Token----------------
Mean TTFT (ms):                          2828.95   
Median TTFT (ms):                        3255.91   
P99 TTFT (ms):                           5577.16   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          25.79     
Median TPOT (ms):                        31.00     
P99 TPOT (ms):                           63.40     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.03     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2896.12   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40916     
Benchmark duration (s):                  10251.32  
Total input tokens:                      9094697   
Total generated tokens:                  7554100   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          887.17    
Output token throughput (tok/s):         736.89    
---------------Time to First Token----------------
Mean TTFT (ms):                          2862.42   
Median TTFT (ms):                        3309.46   
P99 TTFT (ms):                           5615.71   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          26.17     
Median TPOT (ms):                        31.42     
P99 TPOT (ms):                           64.24     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.72     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2948.17   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40903     
Benchmark duration (s):                  10252.24  
Total input tokens:                      9094096   
Total generated tokens:                  7549930   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          887.03    
Output token throughput (tok/s):         736.42    
---------------Time to First Token----------------
Mean TTFT (ms):                          2855.49   
Median TTFT (ms):                        3292.66   
P99 TTFT (ms):                           5641.10   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          26.08     
Median TPOT (ms):                        31.19     
P99 TPOT (ms):                           64.64     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.59     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2919.31   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40902     
Benchmark duration (s):                  10252.91  
Total input tokens:                      9093309   
Total generated tokens:                  7545673   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          886.90    
Output token throughput (tok/s):         735.95    
---------------Time to First Token----------------
Mean TTFT (ms):                          2840.36   
Median TTFT (ms):                        3272.22   
P99 TTFT (ms):                           5599.62   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          25.88     
Median TPOT (ms):                        30.94     
P99 TPOT (ms):                           63.94     
---------------Inter-token Latency----------------
Mean ITL (ms):                           45.25     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2903.91   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40896     
Benchmark duration (s):                  10252.87  
Total input tokens:                      9092426   
Total generated tokens:                  7551480   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          886.82    
Output token throughput (tok/s):         736.52    
---------------Time to First Token----------------
Mean TTFT (ms):                          3186.64   
Median TTFT (ms):                        3712.92   
P99 TTFT (ms):                           6234.53   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          29.32     
Median TPOT (ms):                        35.07     
P99 TPOT (ms):                           71.94     
---------------Inter-token Latency----------------
Mean ITL (ms):                           51.22     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            3298.16   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40902     
Benchmark duration (s):                  10254.00  
Total input tokens:                      9091299   
Total generated tokens:                  7548954   
Request throughput (req/s):              3.99      
Input token throughput (tok/s):          886.61    
Output token throughput (tok/s):         736.20    
---------------Time to First Token----------------
Mean TTFT (ms):                          2885.52   
Median TTFT (ms):                        3350.59   
P99 TTFT (ms):                           5725.02   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          26.43     
Median TPOT (ms):                        31.58     
P99 TPOT (ms):                           65.08     
---------------Inter-token Latency----------------
Mean ITL (ms):                           46.19     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            2968.15   
==================================================
