WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 15:44:05 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
Namespace(backend='vllm', base_url='https://vgpu-test-13.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-9.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-5.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-16.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-15.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-11.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-12.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-1.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-14.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-10.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-8.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-7.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-3.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-4.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-2.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
Namespace(backend='vllm', base_url='https://vgpu-test-6.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=8.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
============ Serving Benchmark Result ============
Successful requests:                     40920     
Benchmark duration (s):                  5180.26   
Total input tokens:                      9092575   
Total generated tokens:                  7560862   
Request throughput (req/s):              7.90      
Input token throughput (tok/s):          1755.24   
Output token throughput (tok/s):         1459.55   
---------------Time to First Token----------------
Mean TTFT (ms):                          10351.90  
Median TTFT (ms):                        10001.63  
P99 TTFT (ms):                           29000.21  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          68.96     
Median TPOT (ms):                        85.05     
P99 TPOT (ms):                           156.79    
---------------Inter-token Latency----------------
Mean ITL (ms):                           120.20    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            8392.82   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40910     
Benchmark duration (s):                  5181.10   
Total input tokens:                      9090982   
Total generated tokens:                  7560578   
Request throughput (req/s):              7.90      
Input token throughput (tok/s):          1754.64   
Output token throughput (tok/s):         1459.26   
---------------Time to First Token----------------
Mean TTFT (ms):                          9476.14   
Median TTFT (ms):                        9839.60   
P99 TTFT (ms):                           25874.41  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          68.43     
Median TPOT (ms):                        84.48     
P99 TPOT (ms):                           155.02    
---------------Inter-token Latency----------------
Mean ITL (ms):                           119.23    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            8314.46   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     35169     
Benchmark duration (s):                  5283.80   
Total input tokens:                      7802855   
Total generated tokens:                  6506502   
Request throughput (req/s):              6.66      
Input token throughput (tok/s):          1476.75   
Output token throughput (tok/s):         1231.41   
---------------Time to First Token----------------
Mean TTFT (ms):                          35983.34  
Median TTFT (ms):                        36499.66  
P99 TTFT (ms):                           74742.19  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          282.14    
Median TPOT (ms):                        141.83    
P99 TPOT (ms):                           806.00    
---------------Inter-token Latency----------------
Mean ITL (ms):                           487.72    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            12131.27  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     34328     
Benchmark duration (s):                  5283.87   
Total input tokens:                      7636152   
Total generated tokens:                  6344822   
Request throughput (req/s):              6.50      
Input token throughput (tok/s):          1445.18   
Output token throughput (tok/s):         1200.79   
---------------Time to First Token----------------
Mean TTFT (ms):                          39021.55  
Median TTFT (ms):                        50949.63  
P99 TTFT (ms):                           83144.98  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          312.62    
Median TPOT (ms):                        172.86    
P99 TPOT (ms):                           801.88    
---------------Inter-token Latency----------------
Mean ITL (ms):                           541.61    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            17538.02  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     35265     
Benchmark duration (s):                  5284.78   
Total input tokens:                      7854909   
Total generated tokens:                  6534650   
Request throughput (req/s):              6.67      
Input token throughput (tok/s):          1486.33   
Output token throughput (tok/s):         1236.50   
---------------Time to First Token----------------
Mean TTFT (ms):                          37225.74  
Median TTFT (ms):                        41529.08  
P99 TTFT (ms):                           83984.20  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          279.20    
Median TPOT (ms):                        141.79    
P99 TPOT (ms):                           794.46    
---------------Inter-token Latency----------------
Mean ITL (ms):                           484.04    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            11970.28  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     33457     
Benchmark duration (s):                  5288.62   
Total input tokens:                      7432737   
Total generated tokens:                  6183066   
Request throughput (req/s):              6.33      
Input token throughput (tok/s):          1405.42   
Output token throughput (tok/s):         1169.13   
---------------Time to First Token----------------
Mean TTFT (ms):                          39612.40  
Median TTFT (ms):                        52351.97  
P99 TTFT (ms):                           82449.86  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          326.37    
Median TPOT (ms):                        197.97    
P99 TPOT (ms):                           825.71    
---------------Inter-token Latency----------------
Mean ITL (ms):                           563.35    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            19882.50  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     32903     
Benchmark duration (s):                  5289.73   
Total input tokens:                      7278622   
Total generated tokens:                  6105204   
Request throughput (req/s):              6.22      
Input token throughput (tok/s):          1375.99   
Output token throughput (tok/s):         1154.16   
---------------Time to First Token----------------
Mean TTFT (ms):                          38950.09  
Median TTFT (ms):                        47795.68  
P99 TTFT (ms):                           76062.43  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          332.60    
Median TPOT (ms):                        220.04    
P99 TPOT (ms):                           842.71    
---------------Inter-token Latency----------------
Mean ITL (ms):                           574.58    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            21282.75  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31438     
Benchmark duration (s):                  5293.63   
Total input tokens:                      6999421   
Total generated tokens:                  5779193   
Request throughput (req/s):              5.94      
Input token throughput (tok/s):          1322.23   
Output token throughput (tok/s):         1091.73   
---------------Time to First Token----------------
Mean TTFT (ms):                          41702.22  
Median TTFT (ms):                        55147.19  
P99 TTFT (ms):                           84449.89  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          360.24    
Median TPOT (ms):                        279.13    
P99 TPOT (ms):                           886.94    
---------------Inter-token Latency----------------
Mean ITL (ms):                           624.05    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            27432.14  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31383     
Benchmark duration (s):                  5294.66   
Total input tokens:                      7000625   
Total generated tokens:                  5795791   
Request throughput (req/s):              5.93      
Input token throughput (tok/s):          1322.20   
Output token throughput (tok/s):         1094.65   
---------------Time to First Token----------------
Mean TTFT (ms):                          41136.01  
Median TTFT (ms):                        52973.76  
P99 TTFT (ms):                           79115.66  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          356.62    
Median TPOT (ms):                        254.44    
P99 TPOT (ms):                           889.46    
---------------Inter-token Latency----------------
Mean ITL (ms):                           617.77    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            25199.64  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     30659     
Benchmark duration (s):                  5296.11   
Total input tokens:                      6822610   
Total generated tokens:                  5694216   
Request throughput (req/s):              5.79      
Input token throughput (tok/s):          1288.23   
Output token throughput (tok/s):         1075.17   
---------------Time to First Token----------------
Mean TTFT (ms):                          42872.23  
Median TTFT (ms):                        60013.93  
P99 TTFT (ms):                           87053.69  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          369.70    
Median TPOT (ms):                        299.57    
P99 TPOT (ms):                           899.75    
---------------Inter-token Latency----------------
Mean ITL (ms):                           638.04    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            29163.70  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31354     
Benchmark duration (s):                  5297.78   
Total input tokens:                      6965915   
Total generated tokens:                  5790443   
Request throughput (req/s):              5.92      
Input token throughput (tok/s):          1314.87   
Output token throughput (tok/s):         1092.99   
---------------Time to First Token----------------
Mean TTFT (ms):                          40872.72  
Median TTFT (ms):                        51810.15  
P99 TTFT (ms):                           74648.35  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          357.88    
Median TPOT (ms):                        256.96    
P99 TPOT (ms):                           893.17    
---------------Inter-token Latency----------------
Mean ITL (ms):                           618.62    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            25054.35  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     35218     
Benchmark duration (s):                  5295.72   
Total input tokens:                      7771833   
Total generated tokens:                  6550690   
Request throughput (req/s):              6.65      
Input token throughput (tok/s):          1467.57   
Output token throughput (tok/s):         1236.98   
---------------Time to First Token----------------
Mean TTFT (ms):                          37993.07  
Median TTFT (ms):                        43601.98  
P99 TTFT (ms):                           90251.41  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          279.95    
Median TPOT (ms):                        142.92    
P99 TPOT (ms):                           788.73    
---------------Inter-token Latency----------------
Mean ITL (ms):                           483.30    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            11845.93  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31609     
Benchmark duration (s):                  5298.66   
Total input tokens:                      7046193   
Total generated tokens:                  5845397   
Request throughput (req/s):              5.97      
Input token throughput (tok/s):          1329.81   
Output token throughput (tok/s):         1103.18   
---------------Time to First Token----------------
Mean TTFT (ms):                          40459.89  
Median TTFT (ms):                        51094.49  
P99 TTFT (ms):                           75701.07  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          354.60    
Median TPOT (ms):                        258.17    
P99 TPOT (ms):                           883.12    
---------------Inter-token Latency----------------
Mean ITL (ms):                           612.87    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            25070.42  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     32206     
Benchmark duration (s):                  5297.97   
Total input tokens:                      7162069   
Total generated tokens:                  5977046   
Request throughput (req/s):              6.08      
Input token throughput (tok/s):          1351.85   
Output token throughput (tok/s):         1128.18   
---------------Time to First Token----------------
Mean TTFT (ms):                          39714.06  
Median TTFT (ms):                        48929.06  
P99 TTFT (ms):                           72548.82  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          341.42    
Median TPOT (ms):                        211.99    
P99 TPOT (ms):                           866.93    
---------------Inter-token Latency----------------
Mean ITL (ms):                           588.83    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            21057.82  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     31288     
Benchmark duration (s):                  5299.49   
Total input tokens:                      6942953   
Total generated tokens:                  5790988   
Request throughput (req/s):              5.90      
Input token throughput (tok/s):          1310.12   
Output token throughput (tok/s):         1092.74   
---------------Time to First Token----------------
Mean TTFT (ms):                          40989.64  
Median TTFT (ms):                        52800.23  
P99 TTFT (ms):                           77011.66  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          359.04    
Median TPOT (ms):                        265.55    
P99 TPOT (ms):                           892.62    
---------------Inter-token Latency----------------
Mean ITL (ms):                           620.43    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            25509.20  
==================================================
============ Serving Benchmark Result ============
Successful requests:                     33931     
Benchmark duration (s):                  5299.92   
Total input tokens:                      7521197   
Total generated tokens:                  6291556   
Request throughput (req/s):              6.40      
Input token throughput (tok/s):          1419.12   
Output token throughput (tok/s):         1187.10   
---------------Time to First Token----------------
Mean TTFT (ms):                          39457.50  
Median TTFT (ms):                        54192.02  
P99 TTFT (ms):                           83381.68  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          318.66    
Median TPOT (ms):                        185.42    
P99 TPOT (ms):                           807.93    
---------------Inter-token Latency----------------
Mean ITL (ms):                           551.59    
Median ITL (ms):                         0.02      
P99 ITL (ms):                            19489.76  
==================================================
