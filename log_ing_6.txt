WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 09-24 11:36:00 _custom_ops.py:18] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
Namespace(backend='vllm', base_url='https://vgpu-test-5.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-3.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-16.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-15.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-7.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-10.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-14.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-9.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-12.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-8.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-2.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-1.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-13.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-11.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-6.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
Namespace(backend='vllm', base_url='https://vgpu-test-4.service-inference.ai', host='localhost', port=8000, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='./ShareGPT_V3_unfiltered_cleaned_split.json', model='meta-llama/Meta-Llama-3-8B-Instruct', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=40960, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, random_input_len=1024, random_output_len=128, random_range_ratio=1.0, request_rate=6.0, seed=0, trust_remote_code=False, disable_tqdm=False, save_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 6.0
============ Serving Benchmark Result ============
Successful requests:                     40948     
Benchmark duration (s):                  6862.84   
Total input tokens:                      9098538   
Total generated tokens:                  7571029   
Request throughput (req/s):              5.97      
Input token throughput (tok/s):          1325.77   
Output token throughput (tok/s):         1103.19   
---------------Time to First Token----------------
Mean TTFT (ms):                          4789.47   
Median TTFT (ms):                        5724.53   
P99 TTFT (ms):                           9056.55   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          43.53     
Median TPOT (ms):                        53.11     
P99 TPOT (ms):                           105.46    
---------------Inter-token Latency----------------
Mean ITL (ms):                           76.00     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5108.92   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40947     
Benchmark duration (s):                  6864.07   
Total input tokens:                      9098366   
Total generated tokens:                  7561979   
Request throughput (req/s):              5.97      
Input token throughput (tok/s):          1325.51   
Output token throughput (tok/s):         1101.68   
---------------Time to First Token----------------
Mean TTFT (ms):                          4950.12   
Median TTFT (ms):                        5820.13   
P99 TTFT (ms):                           9489.80   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          44.97     
Median TPOT (ms):                        53.96     
P99 TPOT (ms):                           112.14    
---------------Inter-token Latency----------------
Mean ITL (ms):                           78.53     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5065.60   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40949     
Benchmark duration (s):                  6864.04   
Total input tokens:                      9098526   
Total generated tokens:                  7571113   
Request throughput (req/s):              5.97      
Input token throughput (tok/s):          1325.54   
Output token throughput (tok/s):         1103.01   
---------------Time to First Token----------------
Mean TTFT (ms):                          5035.32   
Median TTFT (ms):                        5956.70   
P99 TTFT (ms):                           9463.70   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          45.69     
Median TPOT (ms):                        55.08     
P99 TPOT (ms):                           111.79    
---------------Inter-token Latency----------------
Mean ITL (ms):                           79.71     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5174.54   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40953     
Benchmark duration (s):                  6864.65   
Total input tokens:                      9098338   
Total generated tokens:                  7567909   
Request throughput (req/s):              5.97      
Input token throughput (tok/s):          1325.39   
Output token throughput (tok/s):         1102.45   
---------------Time to First Token----------------
Mean TTFT (ms):                          4922.59   
Median TTFT (ms):                        5833.09   
P99 TTFT (ms):                           9367.81   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          44.75     
Median TPOT (ms):                        53.54     
P99 TPOT (ms):                           109.87    
---------------Inter-token Latency----------------
Mean ITL (ms):                           78.18     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5090.49   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40950     
Benchmark duration (s):                  6865.46   
Total input tokens:                      9098189   
Total generated tokens:                  7572386   
Request throughput (req/s):              5.96      
Input token throughput (tok/s):          1325.21   
Output token throughput (tok/s):         1102.97   
---------------Time to First Token----------------
Mean TTFT (ms):                          4835.48   
Median TTFT (ms):                        5806.47   
P99 TTFT (ms):                           9091.47   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          44.10     
Median TPOT (ms):                        53.69     
P99 TPOT (ms):                           107.40    
---------------Inter-token Latency----------------
Mean ITL (ms):                           77.01     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5164.79   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40947     
Benchmark duration (s):                  6865.59   
Total input tokens:                      9097314   
Total generated tokens:                  7565658   
Request throughput (req/s):              5.96      
Input token throughput (tok/s):          1325.06   
Output token throughput (tok/s):         1101.97   
---------------Time to First Token----------------
Mean TTFT (ms):                          4805.39   
Median TTFT (ms):                        5727.44   
P99 TTFT (ms):                           9056.59   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          43.86     
Median TPOT (ms):                        52.88     
P99 TPOT (ms):                           106.18    
---------------Inter-token Latency----------------
Mean ITL (ms):                           76.57     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5076.30   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40950     
Benchmark duration (s):                  6865.29   
Total input tokens:                      9099177   
Total generated tokens:                  7566741   
Request throughput (req/s):              5.96      
Input token throughput (tok/s):          1325.39   
Output token throughput (tok/s):         1102.17   
---------------Time to First Token----------------
Mean TTFT (ms):                          4934.68   
Median TTFT (ms):                        5842.27   
P99 TTFT (ms):                           9561.35   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          44.92     
Median TPOT (ms):                        53.99     
P99 TPOT (ms):                           110.59    
---------------Inter-token Latency----------------
Mean ITL (ms):                           78.38     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5129.87   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40946     
Benchmark duration (s):                  6866.19   
Total input tokens:                      9096563   
Total generated tokens:                  7571037   
Request throughput (req/s):              5.96      
Input token throughput (tok/s):          1324.83   
Output token throughput (tok/s):         1102.66   
---------------Time to First Token----------------
Mean TTFT (ms):                          4877.86   
Median TTFT (ms):                        5789.08   
P99 TTFT (ms):                           9336.72   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          44.42     
Median TPOT (ms):                        54.21     
P99 TPOT (ms):                           108.55    
---------------Inter-token Latency----------------
Mean ITL (ms):                           77.60     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5158.36   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40947     
Benchmark duration (s):                  6865.16   
Total input tokens:                      9097955   
Total generated tokens:                  7562667   
Request throughput (req/s):              5.96      
Input token throughput (tok/s):          1325.24   
Output token throughput (tok/s):         1101.60   
---------------Time to First Token----------------
Mean TTFT (ms):                          4775.77   
Median TTFT (ms):                        5698.10   
P99 TTFT (ms):                           9140.35   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          43.38     
Median TPOT (ms):                        52.60     
P99 TPOT (ms):                           104.78    
---------------Inter-token Latency----------------
Mean ITL (ms):                           75.73     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5016.83   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40943     
Benchmark duration (s):                  6866.19   
Total input tokens:                      9097047   
Total generated tokens:                  7564035   
Request throughput (req/s):              5.96      
Input token throughput (tok/s):          1324.90   
Output token throughput (tok/s):         1101.63   
---------------Time to First Token----------------
Mean TTFT (ms):                          4966.25   
Median TTFT (ms):                        5874.27   
P99 TTFT (ms):                           9421.10   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          45.15     
Median TPOT (ms):                        54.24     
P99 TPOT (ms):                           110.43    
---------------Inter-token Latency----------------
Mean ITL (ms):                           78.79     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5105.56   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40957     
Benchmark duration (s):                  6866.38   
Total input tokens:                      9099585   
Total generated tokens:                  7570938   
Request throughput (req/s):              5.96      
Input token throughput (tok/s):          1325.24   
Output token throughput (tok/s):         1102.61   
---------------Time to First Token----------------
Mean TTFT (ms):                          4937.68   
Median TTFT (ms):                        5870.27   
P99 TTFT (ms):                           9455.41   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          45.03     
Median TPOT (ms):                        54.06     
P99 TPOT (ms):                           108.80    
---------------Inter-token Latency----------------
Mean ITL (ms):                           78.60     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5136.98   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40948     
Benchmark duration (s):                  6866.11   
Total input tokens:                      9098875   
Total generated tokens:                  7571946   
Request throughput (req/s):              5.96      
Input token throughput (tok/s):          1325.19   
Output token throughput (tok/s):         1102.80   
---------------Time to First Token----------------
Mean TTFT (ms):                          4810.44   
Median TTFT (ms):                        5759.85   
P99 TTFT (ms):                           9096.97   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          43.71     
Median TPOT (ms):                        53.61     
P99 TPOT (ms):                           105.77    
---------------Inter-token Latency----------------
Mean ITL (ms):                           76.32     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5096.52   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40945     
Benchmark duration (s):                  6866.58   
Total input tokens:                      9098073   
Total generated tokens:                  7571161   
Request throughput (req/s):              5.96      
Input token throughput (tok/s):          1324.98   
Output token throughput (tok/s):         1102.61   
---------------Time to First Token----------------
Mean TTFT (ms):                          5021.07   
Median TTFT (ms):                        5961.16   
P99 TTFT (ms):                           9720.47   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          45.47     
Median TPOT (ms):                        55.43     
P99 TPOT (ms):                           110.90    
---------------Inter-token Latency----------------
Mean ITL (ms):                           79.35     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5248.57   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40944     
Benchmark duration (s):                  6867.04   
Total input tokens:                      9097269   
Total generated tokens:                  7571160   
Request throughput (req/s):              5.96      
Input token throughput (tok/s):          1324.77   
Output token throughput (tok/s):         1102.54   
---------------Time to First Token----------------
Mean TTFT (ms):                          5027.93   
Median TTFT (ms):                        5977.55   
P99 TTFT (ms):                           9611.42   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          45.82     
Median TPOT (ms):                        55.61     
P99 TPOT (ms):                           112.23    
---------------Inter-token Latency----------------
Mean ITL (ms):                           80.01     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5266.45   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40953     
Benchmark duration (s):                  6867.54   
Total input tokens:                      9098528   
Total generated tokens:                  7569436   
Request throughput (req/s):              5.96      
Input token throughput (tok/s):          1324.86   
Output token throughput (tok/s):         1102.20   
---------------Time to First Token----------------
Mean TTFT (ms):                          5085.43   
Median TTFT (ms):                        5978.83   
P99 TTFT (ms):                           9716.41   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          46.25     
Median TPOT (ms):                        55.68     
P99 TPOT (ms):                           113.02    
---------------Inter-token Latency----------------
Mean ITL (ms):                           80.73     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5213.82   
==================================================
============ Serving Benchmark Result ============
Successful requests:                     40950     
Benchmark duration (s):                  6868.62   
Total input tokens:                      9097803   
Total generated tokens:                  7569455   
Request throughput (req/s):              5.96      
Input token throughput (tok/s):          1324.55   
Output token throughput (tok/s):         1102.03   
---------------Time to First Token----------------
Mean TTFT (ms):                          5477.28   
Median TTFT (ms):                        6574.63   
P99 TTFT (ms):                           10054.45  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          50.27     
Median TPOT (ms):                        61.66     
P99 TPOT (ms):                           117.96    
---------------Inter-token Latency----------------
Mean ITL (ms):                           87.80     
Median ITL (ms):                         0.02      
P99 ITL (ms):                            5979.58   
==================================================
